# ะะฝะฐะปะธะท ะฟัะพะฑะปะตะผั ะบะฐัะตััะฒะฐ ะดะฐะฝะฝัั: Multi-Label vs Single-Label

---

## ๐ ะกะพะดะตัะถะฐะฝะธะต

1. [ะะฒะตะดะตะฝะธะต](#ะฒะฒะตะดะตะฝะธะต)
2. [ะะฑะฝะฐััะถะตะฝะฝัะต ะฟัะพะฑะปะตะผั ั ะดะฐะฝะฝัะผะธ](#ะพะฑะฝะฐััะถะตะฝะฝัะต-ะฟัะพะฑะปะตะผั-ั-ะดะฐะฝะฝัะผะธ)
3. [ะญะบัะฟะตัะธะผะตะฝัั ั Multi-Label ะบะปะฐััะธัะธะบะฐัะธะตะน](#ัะบัะฟะตัะธะผะตะฝัั-ั-multi-label-ะบะปะฐััะธัะธะบะฐัะธะตะน)
4. [ะะตัะตัะพะด ะฝะฐ Single-Label ะฟะพะดัะพะด](#ะฟะตัะตัะพะด-ะฝะฐ-single-label-ะฟะพะดัะพะด)
5. [ะกัะฐะฒะฝะธัะตะปัะฝัะน ะฐะฝะฐะปะธะท ัะตะทัะปััะฐัะพะฒ](#ััะฐะฒะฝะธัะตะปัะฝัะน-ะฐะฝะฐะปะธะท-ัะตะทัะปััะฐัะพะฒ)
6. [ะัะฒะพะดั](#ะฒัะฒะพะดั)

---

## ะะฒะตะดะตะฝะธะต

ะัะธ ะฝะฐัะฐะปะต ะฟัะพะตะบัะฐ ะฟัะตะดะฟะพะปะฐะณะฐะปะพัั ะธัะฟะพะปัะทะพะฒะฐะฝะธะต **multi-label ะบะปะฐััะธัะธะบะฐัะธะธ**, ัะฐะบ ะบะฐะบ ะธััะพะดะฝัะน ะดะฐัะฐัะตั ัะพะดะตัะถะฐะป ะทะฐะฟะธัะธ ั ะผะฝะพะถะตััะฒะตะฝะฝัะผะธ ััะฑัะธะบะฐะผะธ (ะพะดะฝะฐ ะพัะณะฐะฝะธะทะฐัะธั ะผะพะถะตั ะพัะฝะพัะธัััั ะบ ะฝะตัะบะพะปัะบะธะผ ะบะฐัะตะณะพัะธัะผ, ะฝะฐะฟัะธะผะตั: "ะะฐัะต", "ะะฐั", "ะะตััะพัะฐะฝ").

ะะดะฝะฐะบะพ ะฒ ะฟัะพัะตััะต ะฐะฝะฐะปะธะทะฐ ะดะฐะฝะฝัั ะธ ะฟะตัะฒัั ัะบัะฟะตัะธะผะตะฝัะพะฒ ะฑัะปะธ ะพะฑะฝะฐััะถะตะฝั **ัะตััะตะทะฝัะต ะฟัะพะฑะปะตะผั ั ะบะฐัะตััะฒะพะผ ัะฐะทะผะตัะบะธ**, ััะพ ะฟัะธะฒะตะปะพ ะบ ะบัะธัะธัะตัะบะธ ะฝะธะทะบะพะผั ะบะฐัะตััะฒั multi-label ะผะพะดะตะปะตะน.

ะญัะพั ะดะพะบัะผะตะฝั ะพะฟะธััะฒะฐะตั:
- ะะฐะบะธะต ะฟัะพะฑะปะตะผั ะฑัะปะธ ะพะฑะฝะฐััะถะตะฝั
- ะะฐะบะธะต ัะบัะฟะตัะธะผะตะฝัั ะฟัะพะฒะพะดะธะปะธัั
- ะะพัะตะผั ะฑัะป ะฒัะฑัะฐะฝ single-label ะฟะพะดัะพะด
- ะกัะฐะฒะฝะตะฝะธะต ัะตะทัะปััะฐัะพะฒ

---

## ะะฑะฝะฐััะถะตะฝะฝัะต ะฟัะพะฑะปะตะผั ั ะดะฐะฝะฝัะผะธ

### 1. ะกัะฐัะธััะธะบะฐ ะผะฝะพะถะตััะฒะตะฝะฝัั ััะฑัะธะบ
```
ะะฐัะฟัะตะดะตะปะตะฝะธะต ะฟะพ ะบะพะปะธัะตััะฒั ััะฑัะธะบ ะฝะฐ ะทะฐะฟะธัั:

rubric_count    ะะพะปะธัะตััะฒะพ    ะัะพัะตะฝั
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
1               241,073       48.22%   โ Single-label (ัะธัััะต)
2               108,822       21.76%
3               134,734       26.95%   โ Multi-label (ะฟะพัะตะฝัะธะฐะปัะฝัะน ััะผ)
4                10,515        2.10%
5                 4,297        0.86%
6                   410        0.08%
7                    95        0.02%
8                    22        0.00%
9                    13        0.00%
10                    3        0.00%
11                    3        0.00%
12                    1        0.00%   โ 12 ััะฑัะธะบ ั ะะะะะ ะทะฐะฟะธัะธ! ๐คฏ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะัะตะณะพ:          499,988      100.00%

ะก ะพะดะฝะพะน ััะฑัะธะบะพะน:           241,073 (48.22%)
ะก ะผะฝะพะถะตััะฒะตะฝะฝัะผะธ ััะฑัะธะบะฐะผะธ: 258,915 (51.78%)  โ ะะะะะ ะะะะะะะะซ!
```

**ะะปััะตะฒะพะต ะฝะฐะฑะปัะดะตะฝะธะต:** ะะพะปะตะต **51.8%** ะทะฐะฟะธัะตะน ะธะผะตัั ะผะฝะพะถะตััะฒะตะฝะฝัะต ััะฑัะธะบะธ, ััะพ ััะปะพะถะฝัะตั ะทะฐะดะฐัั ะธ ะฒะฝะพัะธั ััะผ.

---

### 2. ะัะธะผะตัั ัะฒะฝะพ ะพัะธะฑะพัะฝะพะน ัะฐะทะผะตัะบะธ

#### ะัะธะผะตั 1: ะะตัะตัะธะฝะฐัะฝะฐั ะบะปะธะฝะธะบะฐ โ ะะฑัะตะฟะธั
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะัะตะฝั ัะพัะพัะฐั ะบะปะธะฝะธะบะฐ, ะพะฑัะฐัะธะปะธัั, ะบะพะณะดะฐ ะทะฐะฑะพะปะตะป ะฝะฐั ะปัะฑะธะผัะธะบ, ะฝะฐั ะบะพัะพัะตะน. 
ะัั ะฒะตัะตัะธะฝะฐัั ะพัะตะฝั ะพัะทัะฒัะธะฒัะต ะปัะดะธ, ะณัะฐะผะพัะฝัะต, ะฒะตะถะปะธะฒัะต, ะฒัะตะณะดะฐ ะธะฝัะตัะตัััััั, 
ะบะฐะบ ัะตะฑั ััะฒััะฒัะตั ะบะพัะธะบ ะฟัะธ ะฟะพะฒัะพัะฝะพะผ ะพะฑัะฐัะตะฝะธะธ..."

ะะฐะทะผะตัะตะฝะฝัะต ััะฑัะธะบะธ: ะะฐั, ะฟะฐะฑ | ะะฐัะต | ะะตััะพัะฐะฝ  โ ะะะกะฃะะ!

ะัะพะฑะปะตะผะฐ: ะัะทัะฒ ะฏะะะ ะฟัะพ ะฒะตัะตัะธะฝะฐัะฝัั ะบะปะธะฝะธะบั, ะฝะพ ัะฐะทะผะตัะตะฝ ะบะฐะบ ะทะฐะฒะตะดะตะฝะธะต ะพะฑัะตะฟะธัะฐ.
```

#### ะัะธะผะตั 2: ะะฒัะพะฒะพะบะทะฐะป โ ะะฐัะต?
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะัะปะธ ะฝะต ะพะดะธะฝ ัะฐะท. ะััััะพ ะธ ะฒะบััะฝะพ"

ะะฐะทะผะตัะตะฝะฝัะต ััะฑัะธะบะธ: ะะฒัะพะฒะพะบะทะฐะป, ะฐะฒัะพััะฐะฝัะธั  โ ะกะะะะะขะะะฌะะ

ะัะพะฑะปะตะผะฐ: ะะพ ัะตะบััั ะฟะพัะพะถะต ะฝะฐ ะบะฐัะต/ัะตััะพัะฐะฝ, ะฝะพ ัะฐะทะผะตัะตะฝะพ ะบะฐะบ ะฐะฒัะพะฒะพะบะทะฐะป.
```

#### ะัะธะผะตั 3: ะะทะฑััะพัะฝะฐั ัะฐะทะผะตัะบะฐ
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะัะตะฝั ะฟัะธััะฝัะน ะฟะตััะพะฝะฐะป! ะัั ัััะบะพ ะธ ะฑััััะพ."

ะะฐะทะผะตัะตะฝะฝัะต ััะฑัะธะบะธ: 
  - ะะฒัะพะผะพะฑะธะปัะฝัะต ะณััะทะพะฟะตัะตะฒะพะทะบะธ
  - ะััะทะพะฒัะต ะฐะฒะธะฐะฟะตัะตะฒะพะทะบะธ  
  - ะัััะตััะบะธะต ััะปัะณะธ  โ 3 ััะฑัะธะบะธ!

ะัะพะฑะปะตะผะฐ: ะะตะฟะพะฝััะฝะพ, ะบะฐะบะฐั ะธะท ััะฑัะธะบ ะดะตะนััะฒะธัะตะปัะฝะพ ัะตะปะตะฒะฐะฝัะฝะฐ. 
ะะตัะพััะฝะพ, ะบะพะผะฟะฐะฝะธั ะฟัะตะดะพััะฐะฒะปัะตั ะฒัะต ััะปัะณะธ, ะฝะพ ะดะปั ะบะปะฐััะธัะธะบะฐัะธะธ ะฟะพ ัะตะบััั 
ะพัะทัะฒะฐ ััะพ ัะพะทะดะฐะตั ััะผ.
```

---

### 3. ะขะพะฟ ะบะพะผะฑะธะฝะฐัะธะน ะผะฝะพะถะตััะฒะตะฝะฝัั ััะฑัะธะบ
```
ะขะพะฟ-20 ัะฐะผัั ัะฐัััั ะบะพะผะฑะธะฝะฐัะธะน:

ะะพะผะฑะธะฝะฐัะธั ััะฑัะธะบ                                              ะะพะปะธัะตััะฒะพ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐัะต;ะะตััะพัะฐะฝ                                                      8,223
ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ;ะกัะฟะตัะผะฐัะบะตั                                      6,244
ะะฐั, ะฟะฐะฑ;ะะฐัะต;ะะตััะพัะฐะฝ                                             4,114
ะะฐะทะฒะปะตะบะฐัะตะปัะฝัะน ัะตะฝัั;ะขะพัะณะพะฒัะน ัะตะฝัั                               3,412
ะััััะพะต ะฟะธัะฐะฝะธะต;ะะฐัะต                                               3,286
ะะฐั, ะฟะฐะฑ;ะะตััะพัะฐะฝ                                                  2,890
ะะพะณัะตะฒะฐั ัััะดะธั;ะะฐัะธะบะผะฐัะตััะบะฐั;ะกะฐะปะพะฝ ะบัะฐัะพัั                       2,720
ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ;ะะฐะณะฐะทะธะฝ ัะพะทัะพะฒะฐัะพะฒ ะธ ะฑััะพะฒะพะน ัะธะผะธะธ;ะกัะฟะตัะผะฐัะบะตั  2,578
ะะฐะณะฐะทะธะฝ ะฐะปะบะพะณะพะปัะฝัั ะฝะฐะฟะธัะบะพะฒ;ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ                     2,223
ะะฒัะพะผะพะนะบะฐ;ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั                                 2,027
```

**ะัะพะฑะปะตะผะฐ 1: ะะตะฟะพัะปะตะดะพะฒะฐัะตะปัะฝะพััั ะฟะพััะดะบะฐ**
```
"ะะฐัะต;ะะตััะพัะฐะฝ"    โ 8,223 ะทะฐะฟะธัะตะน
"ะะตััะพัะฐะฝ;ะะฐัะต"    โ 3,669 ะทะฐะฟะธัะตะน (ะดััะณะฐั ะบะพะผะฑะธะฝะฐัะธั!)

โ ะะดะธะฝะฐะบะพะฒัะต ะฟะพ ัะผััะปั, ะฝะพ ะฟัะตะดััะฐะฒะปะตะฝั ะบะฐะบ ัะฐะทะฝัะต ะบะปะฐััั!
```

**ะัะพะฑะปะตะผะฐ 2: ะกะตะผะฐะฝัะธัะตัะบะธ ะฑะปะธะทะบะธะต ะบะฐัะตะณะพัะธะธ**
```
- ะะฐัะต vs ะะตััะพัะฐะฝ vs ะะฐั, ะฟะฐะฑ
- ะกัะฟะตัะผะฐัะบะตั vs ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ
- ะะฒัะพัะตัะฒะธั vs ะะฒัะพะผะพะนะบะฐ

โ ะัะฐะฝะธัะฐ ะผะตะถะดั ะบะฐัะตะณะพัะธัะผะธ ัะฐะทะผััะฐ, ัะปะพะถะฝะพ ัะฐะทะปะธัะธัั ะฟะพ ัะตะบััั ะพัะทัะฒะฐ.
```

---

### 4. ะกััะฐะฝะฝัะต co-occurrence ััะฑัะธะบ

ะะฝะฐะปะธะท ะฟะพะบะฐะทะฐะป, ััะพ ะฝะตะบะพัะพััะต ััะฑัะธะบะธ ัะฐััะพ ะฒัััะตัะฐัััั ะฒะผะตััะต ะฑะตะท ะปะพะณะธัะตัะบะพะน ัะฒัะทะธ:
```
ะกัะฟะตัะผะฐัะบะตั ัะฐััะพ ะฒัััะตัะฐะตััั ะฒะผะตััะต ั:
  โ ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ                    4,244  (ะปะพะณะธัะฝะพ)
  โ ะะฐะณะฐะทะธะฝ ัะพะทัะพะฒะฐัะพะฒ                   2,578  (ะปะพะณะธัะฝะพ)
  โ ะะฐะณะฐะทะธะฝ ะฐะปะบะพะณะพะปัะฝัั ะฝะฐะฟะธัะบะพะฒ         1,234  (ะปะพะณะธัะฝะพ)
  โ ะะฐะทะฒะปะตะบะฐัะตะปัะฝัะน ัะตะฝัั                 234  (ัััะฐะฝะฝะพ!)
  โ ะะฐัะพะบ                                  89  (ะะงะะะฌ ัััะฐะฝะฝะพ!)

ะะฐัะต ัะฐััะพ ะฒัััะตัะฐะตััั ะฒะผะตััะต ั:
  โ ะะตััะพัะฐะฝ                             8,223  (ะปะพะณะธัะฝะพ)
  โ ะะฐั, ะฟะฐะฑ                             4,114  (ะปะพะณะธัะฝะพ)
  โ ะััััะพะต ะฟะธัะฐะฝะธะต                      3,286  (ะปะพะณะธัะฝะพ)
  โ ะะฐะทะตัะฝะฐั ัะฟะธะปััะธั                      12  (ะะะกะฃะะ!)

ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั ัะฐััะพ ะฒัััะตัะฐะตััั ั:
  โ ะะฒัะพะผะพะนะบะฐ                            2,027  (ะปะพะณะธัะฝะพ)
  โ ะะฒัะพะทะฐะฟัะฐััะธ                           456  (ะปะพะณะธัะฝะพ)
  โ ะะฐะณะฐะทะธะฝ ะผะตะฑะตะปะธ                         34  (ัััะฐะฝะฝะพ!)
  โ ะกะฐะปะพะฝ ะบัะฐัะพัั                          18  (ะะงะะะฌ ัััะฐะฝะฝะพ!)
```

**ะัะฒะพะด:** ะัะธัััััะฒัะตั ะทะฝะฐัะธัะตะปัะฝัะน ััะผ ะฒ ะฒะธะดะต ะฝะตะปะพะณะธัะฝัั ะบะพะผะฑะธะฝะฐัะธะน ััะฑัะธะบ.

---

### 5. ะขะพะฟ-ัะปะพะฒะฐ ะดะปั ะบะฐัะตะณะพัะธะน ัะพะดะตัะถะฐั ััะผ

ะะฝะฐะปะธะท ะฝะฐะธะฑะพะปะตะต ะฒะฐะถะฝัั ัะปะพะฒ (ะฟะพ ะฒะตัะฐะผ LogReg) ะดะปั ะบะฐะถะดะพะน ะบะฐัะตะณะพัะธะธ ะฟะพะบะฐะทะฐะป ัััะฐะฝะฝัะต ัะตะทัะปััะฐัั:

#### ะกัะฟะตัะผะฐัะบะตั
```
ะขะพะฟ-15 ะฒะฐะถะฝัั ัะปะพะฒ:
  โ ะฟััะตัะพัะบะฐ          10.69
  โ ะดะธะบัะธ               7.97
  โ ะผะฐะณะฐะทะธะฝ ะฑะพะปััะพะน     6.80
  โ ะบะฐัะพะบ              6.74  โ ะะพัะตะผั "ะบะฐัะพะบ" ะฒะฐะถะตะฝ ะดะปั ััะฟะตัะผะฐัะบะตัะฐ?!
  โ ะบะฐัะฐัััั           6.46  โ ะ "ะบะฐัะฐัััั"?!
  โ ะบะฐัะฐะปะธัั           6.34
  โ ะบัะฟะฐัััั           6.31  โ ะะพะพะฑัะต ะฝะตะฟะพะฝััะฝะพ!
  โ ะผะฐะบะธัะถ             6.00  โ ะะพัะผะตัะธะบะฐ ะฒ ััะฟะตัะผะฐัะบะตัะต? ะกะพะผะฝะธัะตะปัะฝะพ.
```

**ะะฑัััะฝะตะฝะธะต:** ะกัะฟะตัะผะฐัะบะตัั ัะฐััะพ ัะฐะทะผะตัะตะฝั ะฒะผะตััะต ั "ะะฐัะพะบ" ะธ "ะะฐะทะฒะปะตะบะฐัะตะปัะฝัะน ัะตะฝัั" โ ะผะพะดะตะปั ะฒัััะธะปะฐ ััั ะปะพะถะฝัั ัะฒัะทั.

#### ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั
```
ะขะพะฟ-15 ะฒะฐะถะฝัั ัะปะพะฒ:
  โ ะฐะฒัะพัะฐะปะพะฝ          13.67
  โ ะฐะฒัะพะผะพะฑะธะปะธ          9.98
  โ ัะตัะฒะธั ะฝะฐ           8.78
  โ ัะตัะฒะธัะฝัะน           8.08
  โ ะผะตะฑะตะปั             9.88  โ ะะพัะตะผั "ะผะตะฑะตะปั"?!
  โ ะทะฐัะตะปะตะฝะธะต          9.73  โ "ะะฐัะตะปะตะฝะธะต" ะฒ ะฐะฒัะพัะตัะฒะธัะต?!
  โ ะทะฐััะดะบะธ            7.13  โ ะะพะถะตั ะฑััั ะทะฐััะดะบะธ ะดะปั ัะปะตะบััะพะผะพะฑะธะปะตะน, ะฝะพ ัะพะผะฝะธัะตะปัะฝะพ
```

#### ะะฐัะต
```
ะขะพะฟ-15 ะฒะฐะถะฝัั ัะปะพะฒ:
  โ ะบะฐัะต ะพัะตะฝั          8.44
  โ ะฒะบััะฝะตะนัะธะต          5.46
  โ ัะฐัะปัะบะฐ             4.98
  โ ะตะดะฐ                 4.82
  โ ะปะฐะทะตัะฝะพะน ัะฟะธะปััะธะธ  4.32  โ ะะฐะทะตัะฝะฐั ัะฟะธะปััะธั ะฒ ะบะฐัะต?!
```

**ะัะฒะพะด:** ะจัะผะฝะฐั multi-label ัะฐะทะผะตัะบะฐ ะฟัะธะฒะพะดะธั ะบ ัะพะผั, ััะพ ะผะพะดะตะปั ะฒัััะธะฒะฐะตั **ะปะพะถะฝัะต ะฐััะพัะธะฐัะธะธ** ะผะตะถะดั ัะปะพะฒะฐะผะธ ะธ ะบะฐัะตะณะพัะธัะผะธ.

---

## ะญะบัะฟะตัะธะผะตะฝัั ั Multi-Label ะบะปะฐััะธัะธะบะฐัะธะตะน

ะะตัะผะพััั ะฝะฐ ะพะฑะฝะฐััะถะตะฝะฝัะต ะฟัะพะฑะปะตะผั, ะฑัะปะธ ะฟัะพะฒะตะดะตะฝั ัะบัะฟะตัะธะผะตะฝัั ั multi-label ะบะปะฐััะธัะธะบะฐัะธะตะน.

### ะญะบัะฟะตัะธะผะตะฝั 1: Baseline Multi-Label

**ะะฐัะฐะผะตััั:**
```python
model = OneVsRestClassifier(
    LogisticRegression(
        C=1.0,
        max_iter=1000,
        random_state=42
    )
)
```

**ะะตะทัะปััะฐัั:**
```
ะะตััะธะบะฐ          ะะฝะฐัะตะฝะธะต
โโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Hamming Loss     0.0032     (ะฝะธะทะบะธะน - ัะพัะพัะพ)
Micro F1         0.3752     โ ะะธะทะบะธะน
Macro F1         0.0969     โ ะะะะขะะงะะกะะ ะฝะธะทะบะธะน!
Samples F1       0.3086     โ ะะธะทะบะธะน
Weighted F1      0.3265     โ ะะธะทะบะธะน
```

**ะะตัะฐะปัะฝัะน ะฐะฝะฐะปะธะท ะฟะพ ะบะปะฐััะฐะผ:**
```
ะขะพะฟ-5 ะบะปะฐััะพะฒ ะฟะพ F1:
  ะะฒัะพัะบะพะปะฐ                 0.845  โ
  ะะพััะธะฝะธัะฐ                 0.809  โ
  ะะตััะบะธะน ัะฐะด, ััะปะธ         0.793  โ
  ะกะฒะฐะดะตะฑะฝัะน ัะฐะปะพะฝ           0.766  โ
  ะะฟัะตะบะฐ                    0.753  โ

ะัะพะฑะปะตะผะฝัะต ะบะปะฐััั:
  126 ะบะปะฐััะพะฒ ะธะท 300+ ะธะผะตัั F1 = 0.0  โ ะะะะะะ!
  
  ะัะธะผะตัั ะบะปะฐััะพะฒ ั F1=0.0:
    - ะะฐะณะฐะทะธะฝ ะผะตะฑะตะปะธ
    - ะกััะพะธัะตะปัะฝัะน ะผะฐะณะฐะทะธะฝ
    - ะกะฟะพััะธะฒะฝัะน ะบะพะผะฟะปะตะบั
    - ะะฐะทะฐ ะพัะดััะฐ
    - ะะตะผะฟะธะฝะณ
    - ... ะธ ะตัะต 121 ะบะปะฐัั
```

**ะัะฒะพะด:** Macro F1 = 0.0969 ะพะทะฝะฐัะฐะตั, ััะพ **ะฑะพะปััะธะฝััะฒะพ ะบะปะฐััะพะฒ ะผะพะดะตะปั ะฝะต ะฝะฐััะธะปะฐัั ะฟัะตะดัะบะฐะทัะฒะฐัั ะฒะพะพะฑัะต**. ะะพะดะตะปั ัะฐะฑะพัะฐะตั ัะพะปัะบะพ ะฝะฐ 10-15 ัะฐะผัั ัะฐัััั ะบะปะฐััะฐั.

---

### ะญะบัะฟะตัะธะผะตะฝั 2: ะก ะฑะฐะปะฐะฝัะธัะพะฒะบะพะน ะบะปะฐััะพะฒ

**ะะฐัะฐะผะตััั:**
```python
model = OneVsRestClassifier(
    LogisticRegression(
        C=10.0,
        class_weight='balanced',
        max_iter=1000,
        random_state=42
    )
)
```

**ะะตะทัะปััะฐัั:**
```
ะะตััะธะบะฐ          ะะฝะฐัะตะฝะธะต     vs Baseline
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Micro F1         0.2784       -0.0968  โ ะฅะฃะะ!
Macro F1         0.1739       +0.0770  โ ะัััะต, ะฝะพ ะฒัะต ัะฐะฒะฝะพ ะฝะธะทะบะธะน
Samples F1       0.3290       +0.0204  โ ะงััั ะปัััะต
Weighted F1      0.3012       -0.0253  โ ะฅัะถะต
```

**ะะฝะฐะปะธะท ะฟะพ ะบะฐัะตะณะพัะธะธ "ะะฐัะต":**
```
ะะตััะธะบะฐ          Baseline    Balanced    ะะทะผะตะฝะตะฝะธะต
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Precision        0.543       0.325       -0.218  โ
Recall           0.405       0.881       +0.476  โ
F1-Score         0.464       0.475       +0.011  ~
```

**ะัะฒะพะด:** ะะฐะปะฐะฝัะธัะพะฒะบะฐ ัะฒะตะปะธัะธะปะฐ recall ะทะฐ ััะตั ัะธะปัะฝะพะณะพ ะฟะฐะดะตะฝะธั precision. ะะพะดะตะปั ััะฐะปะฐ ะฟัะตะดัะบะฐะทัะฒะฐัั ัะปะธัะบะพะผ ะผะฝะพะณะพ ะผะตัะพะบ โ ะผะฝะพะณะพ ะปะพะถะฝัั ััะฐะฑะฐััะฒะฐะฝะธะน.

---

### ะญะบัะฟะตัะธะผะตะฝั 3: ะะพะดะฑะพั ะฟะพัะพะณะฐ ะฒะตัะพััะฝะพััะธ

**ะะดะตั:** ะะผะตััะพ ะฟะพัะพะณะฐ 0.5, ะฟะพะฟัะพะฑะพะฒะฐัั ัะฐะทะฝัะต ะฟะพัะพะณะธ ะดะปั multi-label ะฟัะตะดัะบะฐะทะฐะฝะธั.

**ะะตะทัะปััะฐัั:**
```
ะะพัะพะณ    Micro F1    Macro F1    Samples F1    ะะฐัะต Recall    ะะฐัะต Precision
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
0.2      0.4749      0.1513      0.4335  โ     0.8056         0.4866
0.3      0.4622      0.1420      0.4068        0.6765         0.5286
0.4      0.4379      0.1315      0.3760        0.5454         0.5663
0.5      0.4049      0.1192      0.3411        0.4215         0.6021
0.6      0.3673      0.1074      0.3050        0.3024         0.6367

โ ะัััะธะน ะฟะพัะพะณ: 0.2 (Samples F1: 0.4335)
```

**ะัะฒะพะด:** ะะฐะถะต ั ะพะฟัะธะผะฐะปัะฝัะผ ะฟะพัะพะณะพะผ **Samples F1 = 0.4335** ะธ **Macro F1 = 0.1513** โ ััะพ ะบัะธัะธัะตัะบะธ ะฝะธะทะบะธะต ะฟะพะบะฐะทะฐัะตะปะธ ะดะปั ะฟัะฐะบัะธัะตัะบะพะณะพ ะธัะฟะพะปัะทะพะฒะฐะฝะธั.

---

### ะัะธะผะตัั ะฟัะตะดัะบะฐะทะฐะฝะธะน Multi-Label ะผะพะดะตะปะธ (ะปัััะฐั ะฒะตััะธั, ะฟะพัะพะณ=0.2)

#### ะัะธะผะตั 1: ะะตััะพัะฐะฝ (ะะะะะะ)
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะัะปะธัะฝัะน ัะตััะพัะฐะฝ, ะฒะบััะฝะฐั ะตะดะฐ, ะฟัะธััะฝะฐั ะฐัะผะพััะตัะฐ"

ะะถะธะดะฐะตะผัะต ััะฑัะธะบะธ: ะะตััะพัะฐะฝ, ะะฐัะต, ะะฐั ะฟะฐะฑ

ะัะตะดัะบะฐะทะฐะฝะธั ะผะพะดะตะปะธ (ะฟะพัะพะณ=0.2):
  ะะตััะพัะฐะฝ         0.131   โ ะะธะถะต ะฟะพัะพะณะฐ  โ
  ะะฐัะต             0.096   โ ะะธะถะต ะฟะพัะพะณะฐ  โ
  ะะพััะธะฝะธัะฐ        0.016   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะฐั, ะฟะฐะฑ         0.015   โ ะะธะถะต ะฟะพัะพะณะฐ  โ

ะะตะทัะปััะฐั: ะะ ะะะะะกะะะะะะ ะะ ะะะะะ ะฟัะฐะฒะธะปัะฝะพะน ััะฑัะธะบะธ!
```

#### ะัะธะผะตั 2: ะะพััะธะฝะธัะฐ โ ะกัะฟะตัะผะฐัะบะตั (ะะะกะฃะะ)
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะฅะพัะพัะธะน ะพัะตะปั, ัะธัััะต ะฝะพะผะตัะฐ, ะฒะตะถะปะธะฒัะน ะฟะตััะพะฝะฐะป"

ะะถะธะดะฐะตะผัะต ััะฑัะธะบะธ: ะะพััะธะฝะธัะฐ

ะัะตะดัะบะฐะทะฐะฝะธั ะผะพะดะตะปะธ:
  ะกัะฟะตัะผะฐัะบะตั           0.273   โ ะะะะะกะะะะะะ  โ ะะจะะะะ!
  ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ     0.151   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะฐัะต                  0.042   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะพััะธะฝะธัะฐ             0.018   โ ะะธะถะต ะฟะพัะพะณะฐ  โ

ะะตะทัะปััะฐั: ะัะตะดัะบะฐะทะฐะฝ ะกะฃะะะะะะะะะข ะฒะผะตััะพ ะะะกะขะะะะฆะซ!
```

#### ะัะธะผะตั 3: ะะฒัะพัะตัะฒะธั (ะะ ะะะะะะ)
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะััััะพ ะพะฑัะปัะถะธะปะธ ะผะฐัะธะฝั, ะบะฐัะตััะฒะตะฝะฝะพ ะพััะตะผะพะฝัะธัะพะฒะฐะปะธ"

ะะถะธะดะฐะตะผัะต ััะฑัะธะบะธ: ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั

ะัะตะดัะบะฐะทะฐะฝะธั ะผะพะดะตะปะธ:
  ะะตััะพัะฐะฝ                     0.053   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะฐัะต                         0.050   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั     0.040   โ ะะธะถะต ะฟะพัะพะณะฐ  โ

ะะตะทัะปััะฐั: ะะฐะถะต ะฝะต ะฟัะตะดัะบะฐะทะฐะฝะพ!
```

#### ะัะธะผะตั 4: ะะพัะตะนะฝั โ ะัะทะตะน (ะะะกะฃะะ)
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะะบััะฝัะน ะบะพัะต ะธ ะดะตัะตััั, ัััะฝะพะต ะผะตััะพ"

ะะถะธะดะฐะตะผัะต ััะฑัะธะบะธ: ะะพัะตะนะฝั, ะะฐัะต, ะะพะฝะดะธัะตััะบะฐั

ะัะตะดัะบะฐะทะฐะฝะธั ะผะพะดะตะปะธ:
  ะัะทะตะน           0.330   โ ะะะะะกะะะะะะ  โ ะะะะะซะ ะะะกะฃะะ!
  ะะฐัะต            0.079   โ ะะธะถะต ะฟะพัะพะณะฐ  โ
  ะะตััะพัะฐะฝ        0.040   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะพัะตะนะฝั         0.026   โ ะะธะถะต ะฟะพัะพะณะฐ  โ

ะะตะทัะปััะฐั: ะัะตะดัะบะฐะทะฐะฝ ะะฃะะะ ะดะปั ะพัะทัะฒะฐ ะฟัะพ ะบะพัะต ะธ ะดะตัะตััั!
```

#### ะัะธะผะตั 5: ะกัะฟะตัะผะฐัะบะตั (ะะ ะะะะะะ)
```
ะขะตะบัั ะพัะทัะฒะฐ:
"ะัะฟะธะปะธ ะฟัะพะดัะบัั, ะฑะพะปััะพะน ะฒัะฑะพั, ัะฒะตะถะธะต ะพะฒะพัะธ"

ะะถะธะดะฐะตะผัะต ััะฑัะธะบะธ: ะกัะฟะตัะผะฐัะบะตั, ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ

ะัะตะดัะบะฐะทะฐะฝะธั ะผะพะดะตะปะธ:
  ะะฐัะต                  0.075   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ     0.066   โ ะะธะถะต ะฟะพัะพะณะฐ  โ
  ะะตััะพัะฐะฝ              0.033   โ ะะธะถะต ะฟะพัะพะณะฐ
  ะกัะฟะตัะผะฐัะบะตั           0.026   โ ะะธะถะต ะฟะพัะพะณะฐ  โ

ะะตะทัะปััะฐั: ะะธัะตะณะพ ะฝะต ะฟัะตะดัะบะฐะทะฐะฝะพ!
```

**ะัะพะณะพะฒะฐั ััะฐัะธััะธะบะฐ ะฟะพ ะฟัะธะผะตัะฐะผ:**
```
ะัะฐะฒะธะปัะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน:  0 ะธะท 5  (0%)
ะะฑัััะดะฝัั ะพัะธะฑะพะบ:         2 ะธะท 5  (ะกัะฟะตัะผะฐัะบะตั ะฒะผะตััะพ ะะพััะธะฝะธัั, ะัะทะตะน ะฒะผะตััะพ ะะพัะตะนะฝะธ)
ะะต ะฟัะตะดัะบะฐะทะฐะฝะพ ะฒะพะพะฑัะต:    3 ะธะท 5  (60%)
```

---

### Confusion Matrix ะดะปั ัะพะฟ-10 ะบะปะฐััะพะฒ (Multi-Label)
```
                    Predicted
                    ะะฐัะต  ะะตััะพัะฐะฝ  ะะพััะธะฝะธัะฐ  ะกัะฟะตัะผะฐัะบะตั  ...
True:
ะะฐัะต                0.42   0.15      0.08       0.12        ...  โ ะขะพะปัะบะพ 42% ะฟัะฐะฒะธะปัะฝะพ
ะะตััะพัะฐะฝ            0.21   0.38      0.11       0.08        ...  โ ะขะพะปัะบะพ 38% ะฟัะฐะฒะธะปัะฝะพ
ะะพััะธะฝะธัะฐ           0.09   0.07      0.67       0.03        ...  โ 67% - ะปัััะธะน ัะตะทัะปััะฐั
ะกัะฟะตัะผะฐัะบะตั         0.18   0.12      0.04       0.51        ...  โ ะขะพะปัะบะพ 51% ะฟัะฐะฒะธะปัะฝะพ
```

**ะัะฒะพะด:** ะะณัะพะผะฝะฐั ะฟััะฐะฝะธัะฐ ะผะตะถะดั ะบะปะฐััะฐะผะธ. ะัะพะฑะตะฝะฝะพ ะฟัะพะฑะปะตะผะฐัะธัะฝั "ะะฐัะต" ะธ "ะะตััะพัะฐะฝ".

---

## ะะตัะตัะพะด ะฝะฐ Single-Label ะฟะพะดัะพะด

### ะะฑะพัะฝะพะฒะฐะฝะธะต ัะตัะตะฝะธั

ะะพัะปะต ะฐะฝะฐะปะธะทะฐ ัะตะทัะปััะฐัะพะฒ multi-label ัะบัะฟะตัะธะผะตะฝัะพะฒ ะฑัะปะพ ะฟัะธะฝััะพ ัะตัะตะฝะธะต ะฟะตัะตะนัะธ ะฝะฐ **single-label ะบะปะฐััะธัะธะบะฐัะธั** ะฟะพ ัะปะตะดัััะธะผ ะฟัะธัะธะฝะฐะผ:

#### 1. ะัะธัะธัะตัะบะธ ะฝะธะทะบะพะต ะบะฐัะตััะฒะพ multi-label ะผะพะดะตะปะตะน
```
ะัััะธะน ัะตะทัะปััะฐั: Samples F1 = 0.4335, Macro F1 = 0.1513
โ ะะตะฟัะธะตะผะปะตะผะพ ะดะปั ะฟัะฐะบัะธัะตัะบะพะณะพ ะธัะฟะพะปัะทะพะฒะฐะฝะธั
```

#### 2. ะััะพะบะธะน ััะพะฒะตะฝั ััะผะฐ ะฒ multi-label ัะฐะทะผะตัะบะต
```
- 51.8% ะทะฐะฟะธัะตะน ั ะผะฝะพะถะตััะฒะตะฝะฝัะผะธ ััะฑัะธะบะฐะผะธ
- ะะฝะพะณะพ ะพัะธะฑะพัะฝัั ะบะพะผะฑะธะฝะฐัะธะน
- ะะตะฟะพัะปะตะดะพะฒะฐัะตะปัะฝะพััั (ัะฐะทะฝัะน ะฟะพััะดะพะบ ััะฑัะธะบ)
- ะะพะถะฝัะต co-occurrence
```

#### 3. ะะฐะปะธัะธะต ัะธัััั single-label ะดะฐะฝะฝัั
```
48.2% ะทะฐะฟะธัะตะน (241,073) ะธะผะตัั ะะะะฃ ััะฑัะธะบั
โ ะญัะพ ัะธัััะต, ะฝะฐะดะตะถะฝัะต ะดะฐะฝะฝัะต ะดะปั ะพะฑััะตะฝะธั
```

#### 4. ะกะตะผะฐะฝัะธัะตัะบะฐั ะฑะปะธะทะพััั ะผะฝะพะณะธั multi-label ะบะพะผะฑะธะฝะฐัะธะน
```
ะัะธะผะตัั:
  "ะะฐัะต;ะะตััะพัะฐะฝ" โ ัะฐััะพ ะฒะทะฐะธะผะพะทะฐะผะตะฝัะตะผั
  "ะกัะฟะตัะผะฐัะบะตั;ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ" โ ะฟัะฐะบัะธัะตัะบะธ ะพะดะฝะพ ะธ ัะพ ะถะต
  "ะะฒัะพัะตัะฒะธั;ะะฒัะพะผะพะนะบะฐ" โ ัะฐััะพ ะพะดะฝะฐ ะพัะณะฐะฝะธะทะฐัะธั
  
โ ะะพ ะผะฝะพะณะธั ัะปััะฐัั ะดะพััะฐัะพัะฝะพ ะะะะะ ะพัะฝะพะฒะฝะพะน ะบะฐัะตะณะพัะธะธ
```

### ะะตะฐะปะธะทะฐัะธั
```python
# ะจะฐะณ 1: ะคะธะปัััะฐัะธั single-label ะทะฐะฟะธัะตะน
df_single = df[df['rubric_count'] == 1].copy()

print(f"ะะฐะฟะธัะตะน ั ะพะดะฝะพะน ััะฑัะธะบะพะน: {len(df_single):,}")
# ะะตะทัะปััะฐั: 239,840 ะทะฐะฟะธัะตะน

# ะจะฐะณ 2: ะะทะฒะปะตัะตะฝะธะต ะตะดะธะฝััะฒะตะฝะฝะพะน ััะฑัะธะบะธ
df_single['rubric'] = df_single['rubrics_list'].apply(
    lambda x: x[0] if len(x) > 0 else None
)

# ะจะฐะณ 3: ะคะธะปัััะฐัะธั ัะตะดะบะธั ะบะปะฐััะพะฒ ะดะปั ััะฐะฑะธะปัะฝะพััะธ
# ะะปั ML: min_samples = 500
# ะะปั DL: min_samples = 100

# ML ะผะพะดะตะปั
class_counts_ml = df_single['rubric'].value_counts()
valid_classes_ml = class_counts_ml[class_counts_ml >= 500].index
df_ml = df_single[df_single['rubric'].isin(valid_classes_ml)]

print(f"ML: {len(df_ml):,} ะทะฐะฟะธัะตะน, {len(valid_classes_ml)} ะบะปะฐััะพะฒ")
# ะะตะทัะปััะฐั: 197,863 ะทะฐะฟะธัะตะน, 78 ะบะปะฐััะพะฒ

# DL ะผะพะดะตะปั
class_counts_dl = df_single['rubric'].value_counts()
valid_classes_dl = class_counts_dl[class_counts_dl >= 100].index
df_dl = df_single[df_single['rubric'].isin(valid_classes_dl)]

print(f"DL: {len(df_dl):,} ะทะฐะฟะธัะตะน, {len(valid_classes_dl)} ะบะปะฐััะพะฒ")
# ะะตะทัะปััะฐั: 223,591 ะทะฐะฟะธัะตะน, 191 ะบะปะฐัั
```

---

## ะกัะฐะฒะฝะธัะตะปัะฝัะน ะฐะฝะฐะปะธะท ัะตะทัะปััะฐัะพะฒ

### ะัะฝะพะฒะฝัะต ะผะตััะธะบะธ
```
โโโโโโโโโโโโโโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโฌโโโโโโโโโโโโโโโ
โ ะะพะดัะพะด                   โ Samples F1   โ Macro F1     โ Accuracy     โ
โ                          โ (multi-label)โ              โ (single)     โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโค
โ Multi-label (baseline)   โ   0.3086     โ   0.0969  โ โ     N/A      โ
โ Multi-label (balanced)   โ   0.3290     โ   0.1739  โ โ     N/A      โ
โ Multi-label (ะฟะพัะพะณ=0.2)  โ   0.4335     โ   0.1513  โ โ     N/A      โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโผโโโโโโโโโโโโโโโค
โ Single-label LogReg      โ     N/A      โ   0.5630  โ  โ   62.37%  โ  โ
โ Single-label ruBERT      โ     N/A      โ   0.5341  โ  โ   69.54%  โโ โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโดโโโโโโโโโโโโโโโดโโโโโโโโโโโโโโโดโโโโโโโโโโโโโโโ
```

### ะัะธัะพัั ะบะฐัะตััะฒะฐ ะฟัะธ ะฟะตัะตัะพะดะต ะฝะฐ Single-Label
```
ะะตััะธะบะฐ             Multi-label     Single-label    ะัะธัะพัั
                    (ะปัััะธะน)        (LogReg)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Macro F1            0.1513          0.5630          +272%  ๐
Weighted F1         N/A             0.6362          N/A
Accuracy            ~43% (samples)  62.37%          +45%   ๐

                                    (ruBERT)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Macro F1            0.1513          0.5341          +253%  ๐
Weighted F1         N/A             0.6856          N/A
Accuracy            ~43%            69.54%          +62%   ๐๐
```

**ะัะฒะพะด:** ะะตัะตัะพะด ะฝะฐ single-label ะดะฐะป **ะฟัะธัะพัั ะฒ 2.5-2.7 ัะฐะทะฐ** ะฟะพ Macro F1 ะธ **ะฝะฐ 45-62%** ะฟะพ accuracy!

---

### ะะฐัะตััะฒะพ ะฟัะตะดัะบะฐะทะฐะฝะธะน: Multi-Label vs Single-Label

#### ะัะธะผะตั 1: ะะตััะพัะฐะฝ

**Multi-Label (ะฟัะพะฒะฐะป):**
```
ะขะตะบัั: "ะัะปะธัะฝัะน ัะตััะพัะฐะฝ, ะฒะบััะฝะฐั ะตะดะฐ, ะฟัะธััะฝะฐั ะฐัะผะพััะตัะฐ"
ะัะตะดัะบะฐะทะฐะฝะพ: (ะฝะธัะตะณะพ, ะฒัะต ะฒะตัะพััะฝะพััะธ < 0.2)  โ
```

**Single-Label LogReg:**
```
ะขะตะบัั: "ะัะปะธัะฝัะน ัะตััะพัะฐะฝ, ะฒะบััะฝะฐั ะตะดะฐ, ะฟัะธััะฝะฐั ะฐัะผะพััะตัะฐ"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะตััะพัะฐะฝ                  78.2%  โ
    ะะฐัะต                      12.1%
    ะะฐั, ะฟะฐะฑ                   4.3%
```

**Single-Label ruBERT:**
```
ะขะตะบัั: "ะัะปะธัะฝัะน ัะตััะพัะฐะฝ, ะฒะบััะฝะฐั ะตะดะฐ, ะฟัะธััะฝะฐั ะฐัะผะพััะตัะฐ"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะตััะพัะฐะฝ                  91.4%  โโ
    ะะฐัะต                       6.2%
    ะะฐั, ะฟะฐะฑ                   1.8%
```

---

#### ะัะธะผะตั 2: ะะพััะธะฝะธัะฐ

**Multi-Label (ะฐะฑัััะด):**
```
ะขะตะบัั: "ะฅะพัะพัะธะน ะพัะตะปั, ัะธัััะต ะฝะพะผะตัะฐ, ะฒะตะถะปะธะฒัะน ะฟะตััะพะฝะฐะป"
ะัะตะดัะบะฐะทะฐะฝะพ: ะกัะฟะตัะผะฐัะบะตั (27.3%)  โ ะะะกะฃะะ!
```

**Single-Label LogReg:**
```
ะขะตะบัั: "ะฅะพัะพัะธะน ะพัะตะปั, ัะธัััะต ะฝะพะผะตัะฐ, ะฒะตะถะปะธะฒัะน ะฟะตััะพะฝะฐะป"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะพััะธะฝะธัะฐ                 85.6%  โ
    ะฅะพััะตะป                     7.2%
    ะขััะฑะฐะทะฐ                    3.1%
```

**Single-Label ruBERT:**
```
ะขะตะบัั: "ะฅะพัะพัะธะน ะพัะตะปั, ัะธัััะต ะฝะพะผะตัะฐ, ะฒะตะถะปะธะฒัะน ะฟะตััะพะฝะฐะป"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะพััะธะฝะธัะฐ                 94.8%  โโ
    ะัะตะปั                      3.2%
    ะฅะพััะตะป                     1.1%
```

---

#### ะัะธะผะตั 3: ะะพัะตะนะฝั

**Multi-Label (ะฐะฑัััะด):**
```
ะขะตะบัั: "ะะบััะฝัะน ะบะพัะต ะธ ะดะตัะตััั, ัััะฝะพะต ะผะตััะพ"
ะัะตะดัะบะฐะทะฐะฝะพ: ะัะทะตะน (33.0%)  โ ะะะะะซะ ะะะกะฃะะ!
```

**Single-Label LogReg:**
```
ะขะตะบัั: "ะะบััะฝัะน ะบะพัะต ะธ ะดะตัะตััั, ัััะฝะพะต ะผะตััะพ"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะฐัะต                      67.3%  โ
    ะะพัะตะนะฝั                   18.2%
    ะะพะฝะดะธัะตััะบะฐั               9.1%
```

**Single-Label ruBERT:**
```
ะขะตะบัั: "ะะบััะฝัะน ะบะพัะต ะธ ะดะตัะตััั, ัััะฝะพะต ะผะตััะพ"
ะัะตะดัะบะฐะทะฐะฝะพ:
  โ ะะฐัะต                      88.7%  โโ
    ะะพัะตะนะฝั                   7.3%
    ะะพะฝะดะธัะตััะบะฐั               2.9%
```

### Confusion Matrix: Multi-Label vs Single-Label

#### Multi-Label (ัะพะฟ-5 ะบะปะฐััะพะฒ, ะฝะพัะผะฐะปะธะทะพะฒะฐะฝะฝะฐั)
```
                    Predicted
                    ะะฐัะต  ะะตััะพัะฐะฝ  ะะพััะธะฝะธัะฐ  ะกัะฟะตัะผะฐัะบะตั  ะะะก
True:
ะะฐัะต                0.42   0.15      0.08       0.12        0.03  โ
ะะตััะพัะฐะฝ            0.21   0.38      0.11       0.08        0.02  โ
ะะพััะธะฝะธัะฐ           0.09   0.07      0.67       0.03        0.01  โ๏ธ
ะกัะฟะตัะผะฐัะบะตั         0.18   0.12      0.04       0.51        0.05  โ
ะะะก                 0.06   0.04      0.02       0.08        0.73  โ

ะัะพะฑะปะตะผั:
  โข ะะฐัะต: ัะพะปัะบะพ 42% ะฟัะฐะฒะธะปัะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน
  โข ะะตััะพัะฐะฝ: ัะพะปัะบะพ 38% ะฟัะฐะฒะธะปัะฝัั
  โข ะะณัะพะผะฝะฐั ะฟััะฐะฝะธัะฐ ะผะตะถะดั ะะฐัะต, ะะตััะพัะฐะฝ, ะกัะฟะตัะผะฐัะบะตั
```

#### Single-Label LogReg (ัะพะฟ-5 ะบะปะฐััะพะฒ, ะฝะพัะผะฐะปะธะทะพะฒะฐะฝะฝะฐั)
```
                    Predicted
                    ะะฐัะต  ะะตััะพัะฐะฝ  ะะพััะธะฝะธัะฐ  ะกัะฟะตัะผะฐัะบะตั  ะะะก
True:
ะะฐัะต                0.89   0.07      0.01       0.02        0.00  โโ
ะะตััะพัะฐะฝ            0.08   0.87      0.02       0.01        0.00  โโ
ะะพััะธะฝะธัะฐ           0.01   0.01      0.96       0.00        0.00  โโโ
ะกัะฟะตัะผะฐัะบะตั         0.03   0.02      0.01       0.92        0.01  โโโ
ะะะก                 0.01   0.00      0.00       0.02        0.95  โโโ

ะฃะปัััะตะฝะธั:
  โข ะะฐัะต: 89% (+47%)
  โข ะะตััะพัะฐะฝ: 87% (+49%)
  โข ะะพััะธะฝะธัะฐ: 96% (+29%)
  โข ะกัะฟะตัะผะฐัะบะตั: 92% (+41%)
  โข ะะะก: 95% (+22%)
```

#### Single-Label ruBERT (ัะพะฟ-5 ะบะปะฐััะพะฒ, ะฝะพัะผะฐะปะธะทะพะฒะฐะฝะฝะฐั)
```
                    Predicted
                    ะะฐัะต  ะะตััะพัะฐะฝ  ะะพััะธะฝะธัะฐ  ะกัะฟะตัะผะฐัะบะตั  ะะะก
True:
ะะฐัะต                0.94   0.04      0.00       0.01        0.00  โโโ
ะะตััะพัะฐะฝ            0.05   0.92      0.01       0.01        0.00  โโโ
ะะพััะธะฝะธัะฐ           0.00   0.00      0.98       0.00        0.00  โโโ
ะกัะฟะตัะผะฐัะบะตั         0.02   0.01      0.00       0.95        0.01  โโโ
ะะะก                 0.00   0.00      0.00       0.01        0.97  โโโ

ะฃะปัััะตะฝะธั:
  โข ะะฐัะต: 94% (+52%)
  โข ะะตััะพัะฐะฝ: 92% (+54%)
  โข ะะพััะธะฝะธัะฐ: 98% (+31%)
  โข ะกัะฟะตัะผะฐัะบะตั: 95% (+44%)
  โข ะะะก: 97% (+24%)
```

**ะะธะทัะฐะปัะฝะพะต ััะฐะฒะฝะตะฝะธะต:**
```
ะะธะฐะณะพะฝะฐะปั Confusion Matrix (% ะฟัะฐะฒะธะปัะฝัั):

ะะปะฐัั          Multi-Label  โ  Single LogReg  โ  Single ruBERT
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐัะต                42%            89% (+47%)        94% (+52%)
ะะตััะพัะฐะฝ            38%            87% (+49%)        92% (+54%)
ะะพััะธะฝะธัะฐ           67%            96% (+29%)        98% (+31%)
ะกัะฟะตัะผะฐัะบะตั         51%            92% (+41%)        95% (+44%)
ะะะก                 73%            95% (+22%)        97% (+24%)
```

---

### ะัะธะผะตัั ะฟัะฐะฒะธะปัะฝัั ะฟัะตะดัะบะฐะทะฐะฝะธะน Single-Label

#### ะัะธะผะตั 1: ะะฒัะพัะตัะฒะธั
```
ะขะตะบัั: "ะััััะพ ะพะฑัะปัะถะธะปะธ ะผะฐัะธะฝั, ะบะฐัะตััะฒะตะฝะฝะพ ะพััะตะผะพะฝัะธัะพะฒะฐะปะธ"

Multi-Label: ะฝะต ะฟัะตะดัะบะฐะทะฐะฝะพ (ะฒัะต < 0.2)  โ

LogReg:
  โ ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั    73.2%  โ
    ะะฒัะพะผะพะนะบะฐ                   12.4%
    ะจะธะฝะพะผะพะฝัะฐะถ                   8.1%

ruBERT:
  โ ะะฒัะพัะตัะฒะธั, ะฐะฒัะพัะตััะตะฝัั    89.6%  โโ
    ะะฒัะพะผะพะนะบะฐ                    5.3%
    ะจะธะฝะพะผะพะฝัะฐะถ                   3.2%
```

#### ะัะธะผะตั 2: ะกัะฟะตัะผะฐัะบะตั
```
ะขะตะบัั: "ะัะฟะธะปะธ ะฟัะพะดัะบัั, ะฑะพะปััะพะน ะฒัะฑะพั, ัะฒะตะถะธะต ะพะฒะพัะธ"

Multi-Label: ะฝะต ะฟัะตะดัะบะฐะทะฐะฝะพ (ะฒัะต < 0.2)  โ

LogReg:
  โ ะกัะฟะตัะผะฐัะบะตั                 81.7%  โ
    ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ           11.2%
    ะัะพะดัะบัะพะฒัะน ะณะธะฟะตัะผะฐัะบะตั      4.3%

ruBERT:
  โ ะกัะฟะตัะผะฐัะบะตั                 92.4%  โโ
    ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ            5.1%
    ะัะพะดัะบัะพะฒัะน ะณะธะฟะตัะผะฐัะบะตั      1.8%
```

#### ะัะธะผะตั 3: ะะฟัะตะบะฐ
```
ะขะตะบัั: "ะัะฟะธะปะธ ะปะตะบะฐัััะฒะฐ, ะฑััััะพ ะพะฑัะปัะถะธะปะธ, ัะตะฝั ะฝะพัะผะฐะปัะฝัะต"

Multi-Label:
    ะะฐัะต                        0.089  โ
    ะกัะฟะตัะผะฐัะบะตั                 0.067  โ
    ะะฟัะตะบะฐ                      0.043  โ ะะธะถะต ะฟะพัะพะณะฐ

LogReg:
  โ ะะฟัะตะบะฐ                      88.3%  โ
    ะะฐะณะฐะทะธะฝ ะฟัะพะดัะบัะพะฒ            6.2%
    ะกัะฟะตัะผะฐัะบะตั                  3.1%

ruBERT:
  โ ะะฟัะตะบะฐ                      95.7%  โโ
    ะะตะดะธัะธะฝัะบะธะน ัะตะฝัั            2.3%
    ะะปะธะฝะธะบะฐ                      1.2%
```

---

### ะะตัะฐะปัะฝัะน ะฐะฝะฐะปะธะท ะฟะพ ะบะฐัะตะณะพัะธัะผ

#### ะะฐัะตะณะพัะธั: ะะฐัะต

**Multi-Label:**
```
Precision: 0.487  (ะธะท ะฟัะตะดัะบะฐะทะฐะฝะฝัั "ะะฐัะต" ัะพะปัะบะพ 48.7% ะฟัะฐะฒะธะปัะฝัะต)
Recall:    0.806  (ะฝะฐัะปะธ 80.6% ะฒัะตั "ะะฐัะต", ะฝะพ ั ะฑะพะปััะธะผ ััะผะพะผ)
F1-Score:  0.608

ะัะพะฑะปะตะผั:
  โข ะะฝะพะณะพ ะปะพะถะฝัั ััะฐะฑะฐััะฒะฐะฝะธะน (ะะตััะพัะฐะฝ โ ะะฐัะต)
  โข ะััะฐะฝะธัะฐ ั ะะฐัะพะผ, ะะตััะพัะฐะฝะพะผ
```

**Single-Label LogReg:**
```
Precision: 0.872  (+0.385)  โโ
Recall:    0.891  (+0.085)  โ
F1-Score:  0.881  (+0.273)  โโ

ะฃะปัััะตะฝะธั:
  โข Precision ะฒััะพั ะฝะฐ 39% - ะผะตะฝััะต ะปะพะถะฝัั ััะฐะฑะฐััะฒะฐะฝะธะน
  โข Recall ะพััะฐะปัั ะฒััะพะบะธะผ
  โข F1 ะฒััะพั ะฝะฐ 27%
```

**Single-Label ruBERT:**
```
Precision: 0.918  (+0.431)  โโโ
Recall:    0.937  (+0.131)  โโ
F1-Score:  0.927  (+0.319)  โโโ

ะฃะปัััะตะฝะธั:
  โข Precision ะฒััะพั ะฝะฐ 43%
  โข Recall ะฒััะพั ะฝะฐ 13%
  โข F1 ะฒััะพั ะฝะฐ 32% - ะะะะะะะซะ ะฟัะธัะพัั!
```

---

#### ะะฐัะตะณะพัะธั: ะะพััะธะฝะธัะฐ

**Multi-Label:**
```
Precision: 0.789
Recall:    0.668
F1-Score:  0.723

ะัะพะฑะปะตะผั:
  โข ะกัะตะดะฝะธะต ะฟะพะบะฐะทะฐัะตะปะธ
  โข ะััะฐะฝะธัะฐ ั ะฅะพััะตะปะพะผ, ะะฐะทะพะน ะพัะดััะฐ
```

**Single-Label LogReg:**
```
Precision: 0.961  (+0.172)  โโ
Recall:    0.957  (+0.289)  โโ
F1-Score:  0.959  (+0.236)  โโ

ะฃะปัััะตะฝะธั:
  โข ะะดะธะฝ ะธะท ะปัััะธั ะบะปะฐััะพะฒ
  โข ะัะฐะบัะธัะตัะบะธ ะธะดะตะฐะปัะฝะฐั ะบะปะฐััะธัะธะบะฐัะธั (96%)
```

**Single-Label ruBERT:**
```
Precision: 0.978  (+0.189)  โโโ
Recall:    0.981  (+0.313)  โโโ
F1-Score:  0.979  (+0.256)  โโโ

ะฃะปัััะตะฝะธั:
  โข ะะพััะธ ะธะดะตะฐะปัะฝะฐั ะบะปะฐััะธัะธะบะฐัะธั (98%)
  โข ะะธะฝะธะผะฐะปัะฝะฐั ะฟััะฐะฝะธัะฐ ั ะดััะณะธะผะธ ะบะฐัะตะณะพัะธัะผะธ
```

---

#### ะะฐัะตะณะพัะธั: ะะตััะพัะฐะฝ

**Multi-Label:**
```
Precision: 0.521
Recall:    0.385
F1-Score:  0.443

ะัะพะฑะปะตะผั:
  โข ะะธะทะบะฐั precision - ะผะฝะพะณะพ ะปะพะถะฝัั "ะะตััะพัะฐะฝ"
  โข ะะธะทะบะธะน recall - ะฝะต ะฝะฐัะพะดะธั ะผะฝะพะณะธะต ัะตััะพัะฐะฝั
  โข ะกะธะปัะฝะฐั ะฟััะฐะฝะธัะฐ ั ะะฐัะต, ะะฐัะพะผ
```

**Single-Label LogReg:**
```
Precision: 0.843  (+0.322)  โโ
Recall:    0.871  (+0.486)  โโโ
F1-Score:  0.857  (+0.414)  โโโ

ะฃะปัััะตะฝะธั:
  โข ะะณัะพะผะฝัะน ะฟัะธัะพัั ะฟะพ ะฒัะตะผ ะผะตััะธะบะฐะผ
  โข Recall ะฒััะพั ะฝะฐ 49% (!)
  โข F1 ะฒััะพั ะฝะฐ 41%
```

**Single-Label ruBERT:**
```
Precision: 0.895  (+0.374)  โโโ
Recall:    0.919  (+0.534)  โโโ
F1-Score:  0.907  (+0.464)  โโโ

ะฃะปัััะตะฝะธั:
  โข Recall ะฒััะพั ะฝะฐ 53% - ะะะะะะะซะ ะฟัะธัะพัั!
  โข F1 ะฒััะพั ะฝะฐ 46%
  โข ะัะฐะบัะธัะตัะบะธ ัะตัะตะฝะฐ ะฟัะพะฑะปะตะผะฐ ะฟััะฐะฝะธัั ั ะะฐัะต
```

---

### ะกัะฐัะธััะธะบะฐ ะพัะธะฑะพะบ

#### Multi-Label (ัะพะฟ-10 ัะธะฟะพะฒ ะพัะธะฑะพะบ)
```
ะััะธะฝะฝัะน ะบะปะฐัั โ ะัะตะดัะบะฐะทะฐะฝะฝัะน ะบะปะฐัั         ะะพะปะธัะตััะฒะพ ะพัะธะฑะพะบ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐัะต           โ ะะตััะพัะฐะฝ                            892  โ
ะะตััะพัะฐะฝ       โ ะะฐัะต                                743  โ
ะกัะฟะตัะผะฐัะบะตั    โ ะะฐัะต                                456  โ
ะะฐัะต           โ ะกัะฟะตัะผะฐัะบะตั                         387  โ
ะะฐั, ะฟะฐะฑ       โ ะะฐัะต                                321  โ
ะะฐั, ะฟะฐะฑ       โ ะะตััะพัะฐะฝ                            298  โ
ะะตััะพัะฐะฝ       โ ะกัะฟะตัะผะฐัะบะตั                         267  โ
ะะพััะธะฝะธัะฐ      โ ะะฐัะต                                234  โ
ะะฐัะต           โ ะะฐั, ะฟะฐะฑ                            212  โ
ะะฐะณะฐะทะธะฝ        โ ะกัะฟะตัะผะฐัะบะตั                         198  โ

ะะฐััะตัะฝั:
  โข ะกะธะปัะฝะฐั ะฟััะฐะฝะธัะฐ ะฒ ะบะฐัะตะณะพัะธะธ "ะะฑัะตะฟะธั"
  โข ะกัะฟะตัะผะฐัะบะตั ะฟััะฐะตััั ัะพ ะฒัะตะผ ะฟะพะดััะด
  โข ะะตั ัะตัะบะพะน ะณัะฐะฝะธัั ะผะตะถะดั ะฟะพัะพะถะธะผะธ ะบะฐัะตะณะพัะธัะผะธ
```

#### Single-Label LogReg (ัะพะฟ-10 ัะธะฟะพะฒ ะพัะธะฑะพะบ)
```
ะััะธะฝะฝัะน ะบะปะฐัั โ ะัะตะดัะบะฐะทะฐะฝะฝัะน ะบะปะฐัั         ะะพะปะธัะตััะฒะพ ะพัะธะฑะพะบ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐัะต           โ ะะตััะพัะฐะฝ                             87  โ๏ธ
ะะตััะพัะฐะฝ       โ ะะฐัะต                                 63  โ๏ธ
ะััััะพะต ะฟะธัะฐะฝะธะตโ ะะฐัะต                                 42
ะฅะพััะตะป         โ ะะพััะธะฝะธัะฐ                            38
ะะฐะทะฐ ะพัะดััะฐ    โ ะะพััะธะฝะธัะฐ                            34
ะะฐั, ะฟะฐะฑ       โ ะะฐัะต                                 31
ะะฐะณะฐะทะธะฝ        โ ะกัะฟะตัะผะฐัะบะตั                          28
ะะฐัะต           โ ะััััะพะต ะฟะธัะฐะฝะธะต                      24
ะขััะฑะฐะทะฐ        โ ะะฐะทะฐ ะพัะดััะฐ                          21
ะจะบะพะปะฐ          โ ะะตััะบะธะน ัะฐะด                          18

ะะฐััะตัะฝั:
  โข ะัะธะฑะบะธ ะะะะงะะขะะะฌะะ ัะผะตะฝััะธะปะธัั (ะฒ 10 ัะฐะท!)
  โข ะััะฐะฝะธัะฐ ะพััะฐะปะฐัั ัะพะปัะบะพ ะผะตะถะดั ะะะะกะขะะะขะะะฌะะ ะฟะพัะพะถะธะผะธ ะบะฐัะตะณะพัะธัะผะธ
  โข ะะพะณะธัะฝัะต ะพัะธะฑะบะธ (ะฅะพััะตะป โ ะะพััะธะฝะธัะฐ, ะะฐัะต โ ะะตััะพัะฐะฝ)
```

#### Single-Label ruBERT (ัะพะฟ-10 ัะธะฟะพะฒ ะพัะธะฑะพะบ)
```
ะััะธะฝะฝัะน ะบะปะฐัั โ ะัะตะดัะบะฐะทะฐะฝะฝัะน ะบะปะฐัั         ะะพะปะธัะตััะฒะพ ะพัะธะฑะพะบ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ะะฐัะต           โ ะะตััะพัะฐะฝ                             34  โ
ะะตััะพัะฐะฝ       โ ะะฐัะต                                 28  โ
ะััััะพะต ะฟะธัะฐะฝะธะตโ ะะฐัะต                                 19
ะฅะพััะตะป         โ ะะพััะธะฝะธัะฐ                            15
ะะฐะทะฐ ะพัะดััะฐ    โ ะขััะฑะฐะทะฐ                              12
ะะฐั, ะฟะฐะฑ       โ ะะตััะพัะฐะฝ                             11
ะะฐะณะฐะทะธะฝ        โ ะกัะฟะตัะผะฐัะบะตั                          10
ะจะบะพะปะฐ          โ ะะตััะบะธะน ัะฐะด                           9
ะะฐัะต           โ ะะฐั, ะฟะฐะฑ                              8
ะขััะฑะฐะทะฐ        โ ะะฐะทะฐ ะพัะดััะฐ                           7

ะะฐััะตัะฝั:
  โข ะัะธะฑะบะธ ะผะธะฝะธะผะฐะปัะฝั (ะฒ 25 ัะฐะท ะผะตะฝััะต ัะตะผ ั Multi-Label!)
  โข ะัะฐะบัะธัะตัะบะธ ะฒัะต ะพัะธะฑะบะธ - ะผะตะถะดั ัะตะผะฐะฝัะธัะตัะบะธ ะฑะปะธะทะบะธะผะธ ะบะฐัะตะณะพัะธัะผะธ
  โข ะะฑัััะดะฝัั ะพัะธะฑะพะบ ะฝะตั
```

---

### ะัะตะผั ะพะฑััะตะฝะธั ะธ inference
```
ะะพะดะตะปั              ะะฑััะตะฝะธะต        Inference (1000 ะทะฐะฟะธัะตะน)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
Multi-Label         ~45 ัะตะบัะฝะด      ~0.8 ัะตะบัะฝะด
Single LogReg       ~37 ัะตะบัะฝะด      ~0.3 ัะตะบัะฝะด   โ ะััััะตะต
Single ruBERT       ~528 ะผะธะฝัั      ~12 ัะตะบัะฝะด    โ๏ธ ะะตะดะปะตะฝะฝะตะต

ะะพะผะผะตะฝัะฐัะธะน:
  โข LogReg ะฑััััะตะต ะฝะฐ ะพะฑััะตะฝะธะธ ะธ inference
  โข ruBERT ััะตะฑัะตั ะทะฝะฐัะธัะตะปัะฝะพ ะฑะพะปััะต ัะตััััะพะฒ
  โข ะะ ะบะฐัะตััะฒะพ ruBERT ััะพะธั ะทะฐััะฐัะตะฝะฝะพะณะพ ะฒัะตะผะตะฝะธ ะดะปั ะบัะธัะธัะฝัั ะทะฐะดะฐั
```

---

## ะัะฒะพะดั

#### 1. **ะะฐัะตััะฒะพ ะดะฐะฝะฝัั ะบัะธัะธัะฝะพ**
```
ะัะพะฑะปะตะผั ั ะดะฐะฝะฝัะผะธ ะฟัะธะฒะตะปะธ ะบ:
  โ Multi-Label Macro F1 = 0.15  (ะบัะธัะธัะตัะบะธ ะฝะธะทะบะพ)
  โ Single-Label Macro F1 = 0.53-0.56  (ะฒ 3.5 ัะฐะทะฐ ะปัััะต!)

ะัะฒะพะด: ะัััะต ะธะผะตัั ะผะตะฝััะต ะดะฐะฝะฝัั, ะฝะพ ะงะะกะขะซะฅ, 
       ัะตะผ ะฑะพะปััะต ะดะฐะฝะฝัั ั ััะผะพะผ.
```

#### 2. **Multi-Label ะฝะต ะฒัะตะณะดะฐ ะปัััะต**
```
ะขะตะพัะตัะธัะตัะบะธ Multi-Label ะฑะพะปะตะต ะณะธะฑะบะธะน:
  โข ะะพะถะตั ะฟัะตะดัะบะฐะทัะฒะฐัั ะฝะตัะบะพะปัะบะพ ะผะตัะพะบ
  โข ะฃัะธััะฒะฐะตั ัะปะพะถะฝะพััั ัะตะฐะปัะฝะพะณะพ ะผะธัะฐ

ะะ ะฝะฐ ะฟัะฐะบัะธะบะต ั ะทะฐััะผะปะตะฝะฝัะผะธ ะดะฐะฝะฝัะผะธ:
  โข ะะพะดะตะปั ะฒัััะธะฒะฐะตั ะปะพะถะฝัะต ะฐััะพัะธะฐัะธะธ
  โข ะะธะทะบะฐั ัะฒะตัะตะฝะฝะพััั ะฒ ะฟัะตะดัะบะฐะทะฐะฝะธัั
  โข ะะฝะพะณะพ ะฐะฑัััะดะฝัั ะพัะธะฑะพะบ

ะัะฒะพะด: Multi-Label ััะตะฑัะตั ะะงะะะฌ ะบะฐัะตััะฒะตะฝะฝะพะน ัะฐะทะผะตัะบะธ.
```

#### 3. **Single-Label ะดะฐะตั ััะฐะฑะธะปัะฝัะต ัะตะทัะปััะฐัั**
```
ะัะตะธะผััะตััะฒะฐ:
  โ ะะพะปะตะต ัะตัะบะฐั ะทะฐะดะฐัะฐ
  โ ะััะต ัะฒะตัะตะฝะฝะพััั ะฒ ะฟัะตะดัะบะฐะทะฐะฝะธัั
  โ ะะตะฝััะต ะพัะธะฑะพะบ
  โ ะัะพัะต ะธะฝัะตัะฟัะตัะธัะพะฒะฐัั

ะะตะดะพััะฐัะบะธ:
  โ ะขะตััะตััั ะธะฝัะพัะผะฐัะธั ะพ ะดะพะฟะพะปะฝะธัะตะปัะฝัั ััะฑัะธะบะฐั
  โ ะะตะฝััะต ะดะฐะฝะฝัั (48% vs 100%)

ะัะฒะพะด: ะะปั ะฝะฐัะตะน ะทะฐะดะฐัะธ Single-Label ะพะฟัะธะผะฐะปะตะฝ.
```

#### 4. **ruBERT ะฟัะตะฒะพััะพะดะธั ััะฐะดะธัะธะพะฝะฝัะน ML**
```
ruBERT vs LogReg (ะฝะฐ Single-Label):
  โข Accuracy: 69.5% vs 62.4% (+7.1%)  โ
  โข Weighted F1: 0.69 vs 0.64 (+0.05)  โ
  โข Confusion Matrix: 94-98% vs 87-96% ะฝะฐ ะดะธะฐะณะพะฝะฐะปะธ  โ

ะฆะตะฝะฐ: 862x ะผะตะดะปะตะฝะฝะตะต ะพะฑััะตะฝะธะต  โ๏ธ

ะัะฒะพะด: ruBERT ััะพะธั ะธัะฟะพะปัะทะพะฒะฐัั ะบะพะณะดะฐ:
  1. ะัะธัะธัะฝะฐ ะผะฐะบัะธะผะฐะปัะฝะฐั ัะพัะฝะพััั
  2. ะััั GPU ัะตััััั
  3. ะะตะดะบะพะต ะฟะตัะตะพะฑััะตะฝะธะต ะผะพะดะตะปะธ
```